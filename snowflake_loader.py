#!/usr/bin/env python3
"""
Snowflake Data Loader for E-commerce Analytics Pipeline
Loads JSON data files generated by the enhanced app into Snowflake
"""

import snowflake.connector
import json
import logging
import os
import glob
from datetime import datetime
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SnowflakeLoader:
    def __init__(self, config_file='snowflake_config.json'):
        """Initialize with Snowflake configuration"""
        self.config = self.load_config(config_file)
        self.connection = None
        
    def load_config(self, config_file):
        """Load Snowflake configuration"""
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
            
            # Validate required fields
            required_fields = ['user', 'password', 'account']
            for field in required_fields:
                if not config.get(field) or config[field] == f'YOUR_{field.upper()}':
                    raise ValueError(f"Please update {field} in {config_file}")
            
            return config
            
        except Exception as e:
            logger.error(f"Error loading config: {e}")
            raise
    
    def connect(self):
        """Connect to Snowflake"""
        try:
            self.connection = snowflake.connector.connect(
                user=self.config['user'],
                password=self.config['password'],
                account=self.config['account'],
                warehouse='KAFKA_ANALYTICS_WH',
                database='ECOMMERCE_ANALYTICS',
                schema='RAW_DATA'
            )
            logger.info("Connected to Snowflake")
            return True
            
        except Exception as e:
            logger.error(f"Failed to connect to Snowflake: {e}")
            return False
    
    def load_json_files(self, data_directory='data'):
        """Load JSON files from the data directory into Snowflake"""
        try:
            # Get all JSON files from processed directory
            processed_dir = Path(data_directory) / 'processed'
            json_files = list(processed_dir.glob('*.json'))
            
            if not json_files:
                logger.warning(f"No JSON files found in {processed_dir}")
                return False
            
            logger.info(f"Found {len(json_files)} JSON files to process")
            
            cursor = self.connection.cursor()
            
            for json_file in json_files:
                try:
                    logger.info(f"Processing {json_file.name}")
                    
                    # Load JSON data
                    with open(json_file, 'r') as f:
                        events = json.load(f)
                    
                    if not events:
                        logger.warning(f"No events in {json_file.name}")
                        continue
                    
                    # Insert events into RAW_EVENTS table
                    inserted_count = 0
                    for event in events:
                        try:
                            # Prepare event data
                            event_data = {
                                'event_id': event.get('event_id'),
                                'event_type': event.get('event_type'),
                                'session_id': event.get('session_id'),
                                'customer_id': event.get('customer_id'),
                                'timestamp': event.get('timestamp'),
                                'event_data': json.dumps(event),
                                'data_quality_issues': json.dumps(event.get('data_quality_issues', [])),
                                'is_valid': event.get('is_valid', True),
                                'source_file': json_file.name
                            }
                            
                            # Insert into RAW_EVENTS
                            insert_sql = """
                            INSERT INTO RAW_EVENTS (
                                event_id, event_type, session_id, customer_id, 
                                timestamp, event_data, data_quality_issues, 
                                is_valid, source_file
                            ) VALUES (
                                %(event_id)s, %(event_type)s, %(session_id)s, 
                                %(customer_id)s, %(timestamp)s, PARSE_JSON(%(event_data)s), 
                                PARSE_JSON(%(data_quality_issues)s), %(is_valid)s, %(source_file)s
                            )
                            """
                            
                            cursor.execute(insert_sql, event_data)
                            inserted_count += 1
                            
                        except Exception as e:
                            logger.error(f"Error inserting event {event.get('event_id', 'unknown')}: {e}")
                            continue
                    
                    logger.info(f"âœ“ Inserted {inserted_count} events from {json_file.name}")
                    
                    # Move processed file to archive
                    archive_dir = Path(data_directory) / 'archive'
                    archive_dir.mkdir(exist_ok=True)
                    
                    archive_path = archive_dir / f"{json_file.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    json_file.rename(archive_path)
                    logger.info(f"Archived {json_file.name} to {archive_path.name}")
                    
                except Exception as e:
                    logger.error(f"Error processing {json_file.name}: {e}")
                    continue
            
            cursor.close()
            
            # Process raw events into structured tables
            logger.info("Processing raw events into structured tables...")
            self.process_raw_events()
            
            return True
            
        except Exception as e:
            logger.error(f"Error loading JSON files: {e}")
            return False
    
    def process_raw_events(self):
        """Process raw events into structured tables"""
        try:
            cursor = self.connection.cursor()
            
            # Call the stored procedure to process raw events
            cursor.execute("CALL PROCESS_RAW_EVENTS()")
            result = cursor.fetchone()
            logger.info(f"âœ“ Raw events processed: {result[0]}")
            
            cursor.close()
            return True
            
        except Exception as e:
            logger.error(f"Error processing raw events: {e}")
            return False
    
    def get_load_statistics(self):
        """Get statistics about loaded data"""
        try:
            cursor = self.connection.cursor()
            
            # Get raw events count
            cursor.execute("SELECT COUNT(*) FROM RAW_EVENTS WHERE DATE(ingestion_time) = CURRENT_DATE()")
            raw_count = cursor.fetchone()[0]
            
            # Get processed events count
            cursor.execute("USE SCHEMA PROCESSED_DATA")
            
            cursor.execute("SELECT COUNT(*) FROM PAGE_VIEWS WHERE DATE(created_at) = CURRENT_DATE()")
            page_views = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM PRODUCT_INTERACTIONS WHERE DATE(created_at) = CURRENT_DATE()")
            product_interactions = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM PURCHASES WHERE DATE(created_at) = CURRENT_DATE()")
            purchases = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM SEARCHES WHERE DATE(created_at) = CURRENT_DATE()")
            searches = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM USER_ENGAGEMENT WHERE DATE(created_at) = CURRENT_DATE()")
            engagement = cursor.fetchone()[0]
            
            # Get data quality metrics
            cursor.execute("USE SCHEMA ANALYTICS")
            cursor.execute("SELECT * FROM DATA_QUALITY_SUMMARY WHERE date = CURRENT_DATE()")
            quality_data = cursor.fetchone()
            
            stats = {
                'raw_events': raw_count,
                'page_views': page_views,
                'product_interactions': product_interactions,
                'purchases': purchases,
                'searches': searches,
                'user_engagement': engagement,
                'data_quality': quality_data
            }
            
            cursor.close()
            return stats
            
        except Exception as e:
            logger.error(f"Error getting statistics: {e}")
            return None
    
    def close(self):
        """Close the connection"""
        if self.connection:
            self.connection.close()
            logger.info("Connection closed")

def main():
    """Main execution function"""
    logger.info("Starting Snowflake data loading...")
    
    loader = SnowflakeLoader()
    
    try:
        # Connect to Snowflake
        if not loader.connect():
            return
        
        # Load JSON files
        if loader.load_json_files():
            logger.info("âœ“ Data loading completed successfully")
            
            # Get statistics
            stats = loader.get_load_statistics()
            if stats:
                logger.info("ðŸ“Š Load Statistics:")
                logger.info(f"  Raw Events: {stats['raw_events']}")
                logger.info(f"  Page Views: {stats['page_views']}")
                logger.info(f"  Product Interactions: {stats['product_interactions']}")
                logger.info(f"  Purchases: {stats['purchases']}")
                logger.info(f"  Searches: {stats['searches']}")
                logger.info(f"  User Engagement: {stats['user_engagement']}")
                
                if stats['data_quality']:
                    quality = stats['data_quality']
                    logger.info(f"  Data Quality Score: {quality[4]}%")
        else:
            logger.error("Data loading failed")
    
    except KeyboardInterrupt:
        logger.info("Loading interrupted by user")
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
    finally:
        loader.close()

if __name__ == "__main__":
    main()